import json
import time
import random
import requests
import logging
from datetime import datetime, timedelta
from airflow.decorators import dag, task
from airflow.providers.postgres.hooks.postgres import PostgresHook

# –Ü–ú–ü–û–†–¢–£–Ñ–ú–û –£–¢–ò–õ–Ü–¢–£
from utils.ai import ask_ai_json

# --- –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Ø ---
PG_CONN_ID = "recipe_db_postgres"

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –í–æ—Ä–∫–µ—Ä—ñ–≤
BATCH_SIZE = 5   # –ú–∞–ª–µ–Ω—å–∫–∏–π –±–∞—Ç—á, –±–æ AI –º–æ–∂–µ –¥—É–º–∞—Ç–∏ –¥–æ–≤–≥–æ
CONCURRENCY = 3  # –ø–∞—Ä–∞–ª–µ–ª—å–Ω—ñ –ø—Ä–æ—Ü–µ—Å–∏

logger = logging.getLogger("airflow.task")

@dag(
    dag_id="5_product_enricher",
    start_date=datetime(2023, 1, 1),
    schedule=None,
    catchup=False,
    tags=["enrichment", "ai", "sharded"],
    max_active_tasks=CONCURRENCY
)
def product_enricher():
    @task
    def sync_orphaned_products():
        """
        –ó–Ω–∞—Ö–æ–¥–∏—Ç—å –ø—Ä–æ–¥—É–∫—Ç–∏, —è–∫–∏—Ö –Ω–µ–º–∞—î –≤ —á–µ—Ä–∑—ñ (—Å–∏—Ä–æ—Ç–∏).
        1. –Ø–∫—â–æ —É –ø—Ä–æ–¥—É–∫—Ç—É –Ω–µ–º–∞—î URL -> –≥–µ–Ω–µ—Ä—É—î 'internal://product/<id>'.
        2. –î–æ–¥–∞—î —ó—Ö —É —á–µ—Ä–≥—É –∑—ñ —Å—Ç–∞—Ç—É—Å–æ–º DONE (—Å–∫—Ä–∞–ø–∏—Ç–∏ –Ω–µ —Ç—Ä–µ–±–∞) —ñ AI WAITING.
        """
        pg_hook = PostgresHook(postgres_conn_id=PG_CONN_ID)
        conn = pg_hook.get_conn()
        cursor = conn.cursor()

        # –ö–†–û–ö 1: –ó–∞–ø–æ–≤–Ω—é—î–º–æ –ø—É—Å—Ç—ñ URL –≤ —Ç–∞–±–ª–∏—Ü—ñ products —Ç–µ—Ö–Ω—ñ—á–Ω–∏–º–∏ –ø–æ—Å–∏–ª–∞–Ω–Ω—è–º–∏
        # –¶–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ, —â–æ–± –ø—Ä–∞—Ü—é–≤–∞–≤ JOIN –ø–æ original_url
        cursor.execute("""
            UPDATE products
            SET original_url = 'internal://product/' || id
            WHERE original_url IS NULL;
        """)
        if cursor.rowcount > 0:
            logger.info(f"üîß Generated technical URLs for {cursor.rowcount} products.")

        # –ö–†–û–ö 2: –í—Å—Ç–∞–≤–ª—è—î–º–æ –≤ —á–µ—Ä–≥—É —Ç–∏—Ö, –∫–æ–≥–æ —Ç–∞–º —â–µ –Ω–µ–º–∞—î
        # –°—Ç–∞—Ç—É—Å 'DONE' –æ–∑–Ω–∞—á–∞—î "–°–∫—Ä–∞–ø—ñ–Ω–≥ –ø—Ä–æ–ø—É—â–µ–Ω–æ/–∑–∞–≤–µ—Ä—à–µ–Ω–æ", –º–æ–∂–Ω–∞ –π—Ç–∏ –¥–æ AI
        cursor.execute("""
            INSERT INTO product_queue (url, status, created_at, updated_at)
            SELECT original_url, 'DONE', NOW(), NOW()
            FROM products p
            WHERE NOT EXISTS (
                SELECT 1 FROM product_queue q WHERE q.url = p.original_url
            );
        """)
        
        if cursor.rowcount > 0:
            logger.info(f"üì• Added {cursor.rowcount} orphaned products to AI Queue.")
        else:
            logger.info("‚úÖ No orphans found. Queue is in sync.")

        conn.commit()

    @task(retries=3, retry_delay=timedelta(seconds=30))
    def worker_task(worker_id: int):
        pg_hook = PostgresHook(postgres_conn_id=PG_CONN_ID)
        conn = pg_hook.get_conn()
        cursor = conn.cursor()

        logger.info(f"Worker #{worker_id} looking for 'DONE' tasks...")

        while True:
            # 1. –ó–ê–ë–ò–†–ê–Ñ–ú–û –†–û–ë–û–¢–£ (Atomic Lock)
            # - –Ø–∫—â–æ —Å—Ç–∞—Ç—É—Å DONE (–ø–µ—Ä—à–∏–π –∑–∞–ø—É—Å–∫ AI) -> —Å–∫–∏–¥–∞—î–º–æ attempts –Ω–∞ 0
            # - –Ø–∫—â–æ —Å—Ç–∞—Ç—É—Å ENRICH_ERROR (—Ä–µ—Ç—Ä–∞–π) -> —ñ–Ω–∫—Ä–µ–º–µ–Ω—Ç—É—î–º–æ attempts
            cursor.execute(f"""
                UPDATE product_queue
                SET status = 'ENRICH_PROCESSING', 
                    updated_at = NOW(),
                    error_message = NULL
                WHERE url IN (
                    SELECT url FROM product_queue
                    WHERE status = 'DONE'
                    LIMIT {BATCH_SIZE}
                    FOR UPDATE SKIP LOCKED
                )
                RETURNING url;
            """)

            locked_urls = [row[0] for row in cursor.fetchall()]
            # –ö–æ–º—ñ—Ç–∏–º–æ –æ–¥—Ä–∞–∑—É, —â–æ–± –≤—ñ–¥–ø—É—Å—Ç–∏—Ç–∏ –±–∞–∑—É.
            # –¢–µ–ø–µ—Ä —Ü—ñ —Ä—è–¥–∫–∏ –º–∞—é—Ç—å —Å—Ç–∞—Ç—É—Å 'ENRICH_PROCESSING' —ñ –Ω—ñ—Ö—Ç–æ —ñ–Ω—à–∏–π —ó—Ö –Ω–µ –≤—ñ–∑—å–º–µ.
            conn.commit()
            
            if not locked_urls:
                logger.info("üí§ No 'PARSED_DONE' tasks found. Finishing.")
                break

            logger.info(f"üîí Locked {len(locked_urls)} products. Processing...")

            try:
                # 2. –ì–û–¢–£–Ñ–ú–û –î–ê–ù–Ü –î–õ–Ø AI
                cursor.execute("""
                    SELECT id, name, original_url FROM products 
                    WHERE original_url = ANY(%s)
                """, (locked_urls,))
                
                rows = cursor.fetchall()
                # –°–ª–æ–≤–Ω–∏–∫–∏ –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –ø–æ—à—É–∫—É
                products_list = [{"id": r[0], "name": r[1]} for r in rows]
                url_map = {r[0]: r[2] for r in rows} # ID -> URL
                
                if not products_list:
                    # –Ø–∫—â–æ URL —î –≤ —á–µ—Ä–∑—ñ, –∞ –ø—Ä–æ–¥—É–∫—Ç—ñ–≤ –Ω–µ–º–∞—î - –∑–∞–∫—Ä–∏–≤–∞—î–º–æ –∑–∞–¥–∞—á—É –∑ –ø–æ–º–∏–ª–∫–æ—é
                    cursor.execute("UPDATE product_queue SET status='ENRICH_ERROR', error_message='No product data' WHERE url = ANY(%s)", (locked_urls,))
                    conn.commit()
                    continue

                # 3. AI REQUEST (–û–î–ò–ù –ó–ê–ü–ò–¢ –ù–ê –í–°–Æ –ü–ê–ß–ö–£!)
                # --- 3. –§–û–†–ú–£–Ñ–ú–û –ü–†–û–ú–ü–¢ ---
                prompt = f"""
                –¢–∏ ‚Äî –µ–∫—Å–ø–µ—Ä—Ç-—Ç–æ–≤–∞—Ä–æ–∑–Ω–∞–≤–µ—Ü—å (–∫–æ–Ω—Ç–µ–∫—Å—Ç: –£–∫—Ä–∞—ó–Ω–∞). 
                –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –≤—Ö—ñ–¥–Ω–∏–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–¥—É–∫—Ç—ñ–≤.
                –ü–æ–≤–µ—Ä–Ω–∏ –õ–ò–®–ï –≤–∞–ª—ñ–¥–Ω–∏–π JSON-—Å–ø–∏—Å–æ–∫. –ñ–æ–¥–Ω–æ–≥–æ Markdown (```json), –∂–æ–¥–Ω–∏—Ö –ø–æ—è—Å–Ω–µ–Ω—å.

                –ü—Ä–∞–≤–∏–ª–∞ –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –ø–æ–ª—ñ–≤:
                1. "tags": –º–∞—Å–∏–≤ –∫–ª—é—á–æ–≤–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –ø—Ä–æ–¥—É–∫—Ç—É —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é, –∑ –≤–µ–ª–∏–∫–æ—ó –ª—ñ—Ç–µ—Ä–∏, —â–æ –æ–ø–∏—Å—É—î —Ç–∏–ø, –∫–∞—Ç–µ–≥–æ—Ä—ñ—é –∞–±–æ –≤–ª–∞—Å—Ç–∏–≤—ñ—Å—Ç—å –ø—Ä–æ–¥—É–∫—Ç—É.
                   - –í–∫–ª—é—á–∞–π **–∑–∞–≥–∞–ª—å–Ω—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó**: –ú–æ–ª–æ—á–Ω–µ, –ú‚Äô—è—Å–æ, –û–≤–æ—á—ñ, –§—Ä—É–∫—Ç–∏, –í–∏–ø—ñ—á–∫–∞, –ö—Ä—É–ø–∏, –ö–æ–Ω—Å–µ—Ä–≤–∏, –ù–∞–ø–æ—ó —Ç–æ—â–æ.
                   - –í–∫–ª—é—á–∞–π –ø—ñ–¥–∫–∞—Ç–µ–≥–æ—Ä—ñ—é –∞–±–æ –±—ñ–ª—å—à —É–∑–∞–≥–∞–ª—å–Ω–µ–Ω–∞ –Ω–∞–∑–≤–∞ –ø—Ä–æ–¥—É–∫—Ç—É: –°–≤–∏–Ω–∏–Ω–∞, –ö—É—Ä—è—Ç–∏–Ω–∞, –°–∏—Ä, –ö–∞—Ä—Ç–æ–ø–ª—è, –¶–∏–±—É–ª—è, –í–∞—Ä–µ–Ω–Ω—è, –ü–∞—Å—Ç–∞ —Ç–æ—â–æ.
                   - –í–∫–ª—é—á–∞–π –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: "–õ–∞–∫—Ç–æ–∑–∞", "–ì–ª—é—Ç–µ–Ω" —Ç–æ—â–æ.
                   - –ù–µ –¥–æ–¥–∞–≤–∞–π –Ω–∞–∑–≤—É –æ–∫—Ä–µ–º–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞: "–°–∏—Ä –º–∞—Å–∫–∞—Ä–ø–æ–Ω–µ", "–ê—Ä–æ–º–∞—Ç–Ω–∞ –∑–µ–ª–µ–Ω—å", "–ì—Ä–∞–Ω—É–ª—å–æ–≤–∞–Ω–∏–π —á–∞—Å–Ω–∏–∫" —Ç–æ—â–æ.
                   –ü—Ä–∏–∫–ª–∞–¥: ["–ú–æ–ª–æ—á–Ω–µ", "–õ–∞–∫—Ç–æ–∑–∞", "–ú–æ–ª–æ–∫–æ"], ["–ú'—è—Å–æ", "–°–≤–∏–Ω–∏–Ω–∞"]
                
                2. "season_peak":
                   - –Ø–∫—â–æ –ø—Ä–æ–¥—É–∫—Ç –º–∞—î –≤–∏—Ä–∞–∂–µ–Ω–∏–π —Å–µ–∑–æ–Ω (–∫–∞–≤—É–Ω, –≥–∞—Ä–±—É–∑, –º–æ–ª–æ–¥–∞ –∫–∞—Ä—Ç–æ–ø–ª—è): –ø–æ–≤–µ—Ä–Ω–∏ –º–∞—Å–∏–≤ –º—ñ—Å—è—Ü—ñ–≤ [6, 7, 8, ...].
                   - –Ø–∫—â–æ –ø—Ä–æ–¥—É–∫—Ç –¥–æ—Å—Ç—É–ø–Ω–∏–π —Ç–∞ –¥–µ—à–µ–≤–∏–π —É–≤–µ—Å—å —Ä—ñ–∫ (—Å—ñ–ª—å, —Ü—É–∫–æ—Ä, –∫—Ä—É–ø–∏, –º–∞–∫–∞—Ä–æ–Ω–∏, –∫—É—Ä–∫–∞, –±–∞–Ω–∞–Ω): –ø–æ–≤–µ—Ä–Ω–∏ –ø–æ—Ä–æ–∂–Ω—ñ–π –º–∞—Å–∏–≤ [].

                –í–•–Ü–î–ù–Ü –î–ê–ù–Ü:
                {json.dumps(products_list, ensure_ascii=False)}

                –û–ß–Ü–ö–£–í–ê–ù–ò–ô –§–û–†–ú–ê–¢ –í–Ü–î–ü–û–í–Ü–î–Ü:
                [
                  {{"id": 10, "tags": ["–§—Ä—É–∫—Ç–∏", "–¶–∏—Ç—Ä—É—Å–æ–≤—ñ"], "season_peak": [11, 12, 1]}},
                  {{"id": 20, "tags": ["–ú–æ–ª–æ—á–Ω–µ", "–õ–∞–∫—Ç–æ–∑–∞", "–ú–æ–ª–æ–∫–æ"], "season_peak": []}}
                ]
                """
                print(prompt)
                ai_response = ask_ai_json(prompt)

                if not ai_response or not isinstance(ai_response, list):
                    error_msg = "AI returned None or invalid JSON"
                    logger.error(f"[FAIL]: {error_msg}")
                    # –∑—Ä–æ–±–∏—Ç–∏ –∑–∞–ø–∏—Å –≤ –±–¥ –ø–æ–º–∏–ª–∫–∏
                
                # --- 4. –û–ë–†–û–ë–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í ---
                product_updates = []
                tag_ops = [] 
                processed_ids = set()

                for item in ai_response:
                    p_id = item.get("id")
                    if p_id not in url_map: continue

                    # –°–µ–∑–æ–Ω–Ω—ñ—Å—Ç—å
                    raw_season = item.get("season_peak")
                    clean_season = []
                    if raw_season:
                        clean_season = [int(m) for m in raw_season if isinstance(m, int) and 1 <= m <= 12]
                    product_updates.append((clean_season, p_id))

                    # –¢–µ–≥–∏
                    tags = item.get("tags", [])
                    for t_name in tags:
                        clean_name = str(t_name).strip().capitalize()
                        
                        # –¢–∏–ø 'product_cat' –¥–ª—è –≤—Å—å–æ–≥–æ, —â–æ –ø—Ä–∏–π—à–ª–æ
                        tag_ops.append((clean_name, "product_cat", p_id))
                    
                    processed_ids.add(p_id)

                # --- 6. –ó–ê–ü–ò–° ---
                
                # A. –í—Å—Ç–∞–≤–∫–∞ —Ç–µ–≥—ñ–≤ (—Ç–∏–ø –∑–∞–≤–∂–¥–∏ product_cat)
                unique_tags = {(t[0], t[1]) for t in tag_ops}
                if unique_tags:
                    cursor.executemany("""
                        INSERT INTO tags (name, type) VALUES (%s, %s)
                        ON CONFLICT (name) DO UPDATE 
                        SET type = EXCLUDED.type 
                        WHERE tags.type = 'general';
                    """, list(unique_tags))

                # B. –õ—ñ–Ω–∫–æ–≤–∫–∞
                all_tag_names = list({t[0] for t in tag_ops})
                tag_id_map = {}
                if all_tag_names:
                    cursor.execute("SELECT name, id FROM tags WHERE name = ANY(%s)", (all_tag_names,))
                    tag_id_map = {row[0]: row[1] for row in cursor.fetchall()}

                links_to_insert = []
                for t_name, _, p_id in tag_ops:
                    if t_name in tag_id_map:
                        links_to_insert.append((p_id, tag_id_map[t_name]))
                
                if links_to_insert:
                    cursor.executemany("INSERT INTO product_tags (product_id, tag_id) VALUES (%s, %s) ON CONFLICT DO NOTHING;", links_to_insert)

                # C. –û–Ω–æ–≤–ª–µ–Ω–Ω—è
                if product_updates:
                    cursor.executemany("UPDATE products SET seasonality = %s WHERE id = %s;", product_updates)

                # D. –°—Ç–∞—Ç—É—Å–∏
                success_urls = [url_map[pid] for pid in processed_ids]
                failed = list(set(locked_urls) - set(success_urls))
                
                if success_urls:
                    cursor.execute("UPDATE product_queue SET status='ENRICH_DONE', updated_at=NOW() WHERE url = ANY(%s)", (success_urls,))
                if failed:
                    cursor.execute("UPDATE product_queue SET status='ENRICH_ERROR', error_message='AI missed item' WHERE url = ANY(%s)", (failed,))

                conn.commit()
                logger.info(f"‚úÖ Batch: {len(success_urls)} OK")

            except Exception as e:
                # –û–±—Ä–æ–±–∫–∞ –ø–æ–º–∏–ª–∫–∏ –≤—Å—å–æ–≥–æ –±–∞—Ç—á—É
                conn.rollback()
                logger.error(f"‚ùå Batch Failed: {e}")
                cursor.execute("UPDATE product_queue SET status='ENRICH_ERROR', error_message=%s WHERE url = ANY(%s)", (str(e)[:200], locked_urls))
                conn.commit()
                logger.error(f"[OK]: {ai_response}")
            #break
                
    # –õ–ê–ù–¶–Æ–ñ–û–ö –ó–ê–ü–£–°–ö–£
    # 1. –°–ø–æ—á–∞—Ç–∫—É —Å–∏–Ω—Ö—Ä–æ–Ω—ñ–∑—É—î–º–æ —Å–∏—Ä—ñ—Ç
    sync = sync_orphaned_products()
    
    # 2. –ü–æ—Ç—ñ–º –∑–∞–ø—É—Å–∫–∞—î–º–æ –≤–æ—Ä–∫–µ—Ä—ñ–≤
    workers = worker_task.expand(worker_id=list(range(CONCURRENCY)))

    sync >> workers
product_enricher()
