import json
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import hashlib

from airflow.decorators import dag, task
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.providers.amazon.aws.hooks.s3 import S3Hook

# ĞºĞ¾Ğ¼ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ¸ Ğ¾Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ, Ğ½Ñƒ Ñ– Ñ‰Ğ¾ Ğ¾Ğ½Ğ¾Ğ²Ğ¸Ğ»Ğ¾ÑÑŒ?

# --- ĞšĞĞĞ¤Ğ†Ğ“Ğ£Ğ ĞĞ¦Ğ†Ğ¯ ---
PG_CONN_ID = "recipe_db_postgres"
S3_CONN_ID = "minio_s3_storage"
BUCKET_IMAGES = "recipe-images"

# Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº URL Ğ´Ğ»Ñ ÑĞºÑ€Ğ°Ğ¿Ñ–Ğ½Ğ³Ñƒ (Ğ¼Ğ¾Ğ¶Ğ½Ğ° Ñ€Ğ¾Ğ·ÑˆĞ¸Ñ€Ğ¸Ñ‚Ğ¸)
URLS_TO_SCRAPE = [
    "https://klopotenko.com/ukrainskyi-borshch-na-svynyachomu-rebri/",
    "https://klopotenko.com/banosh-z-brynzoyu-i-shkvarkamy/"
]

@dag(
    dag_id="test_recipe_scraper",
    start_date=datetime(2023, 1, 1),
    schedule=None,
    catchup=False,
    tags=["production", "recipes", "scraping"]
)
def scraper_dag():

    @task
    def init_db_schema():
        """Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ” Ñ„Ñ–Ğ½Ğ°Ğ»ÑŒĞ½Ñƒ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ Ğ´Ğ»Ñ Ñ€ĞµÑ†ĞµĞ¿Ñ‚Ñ–Ğ²"""
        pg_hook = PostgresHook(postgres_conn_id=PG_CONN_ID)
        pg_hook.run("""
            CREATE TABLE IF NOT EXISTS parsed_recipes (
                id SERIAL PRIMARY KEY,
                title VARCHAR(255),
                url TEXT UNIQUE,
                image_minio_path VARCHAR(255),
                ingredients TEXT,
                parsed_at TIMESTAMP DEFAULT NOW()
            );
        """)
        print("âœ… Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ parsed_recipes Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°.")

    @task
    def extract_recipe_data(urls: list) -> list:
        """
        Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ÑƒÑ” HTML Ñ‚Ğ° Ğ¿Ğ°Ñ€ÑĞ¸Ñ‚ÑŒ Ğ¹Ğ¾Ğ³Ğ¾ Ğ·Ğ° Ğ´Ğ¾Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ¾Ñ BeautifulSoup.
        """
        extracted_data = []
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }

        for url in urls:
            try:
                print(f"ğŸ” Ğ¡ĞºĞ°Ğ½ÑƒÑ”Ğ¼Ğ¾: {url}")
                response = requests.get(url, headers=headers)
                response.raise_for_status() # ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ° Ğ½Ğ° Ğ¿Ğ¾Ğ¼Ğ¸Ğ»ĞºĞ¸ 404/500

                soup = BeautifulSoup(response.content, 'html.parser')

                # --- Ğ›ĞĞ“Ğ†ĞšĞ ĞŸĞĞ Ğ¡Ğ˜ĞĞ“Ğ£ (ĞŸĞ†Ğ” Ğ¡ĞĞ™Ğ¢ KLOPOTENKO) ---
                
                # 1. ĞĞ°Ğ·Ğ²Ğ° ÑÑ‚Ñ€Ğ°Ğ²Ğ¸
                title_tag = soup.find('div', class_='recipe-header__main-info')
                title = title_tag.find('h1').text.strip() if title_tag else "ĞĞµĞ²Ñ–Ğ´Ğ¾Ğ¼Ğ° ÑÑ‚Ñ€Ğ°Ğ²Ğ°"

                # 2. Ğ“Ğ¾Ğ»Ğ¾Ğ²Ğ½Ğµ Ñ„Ğ¾Ñ‚Ğ¾ (ÑˆÑƒĞºĞ°Ñ”Ğ¼Ğ¾ Ğ² Ğ±Ğ»Ğ¾Ñ†Ñ– Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ)
                img_tag = soup.find('div', class_='recipe-header__img')
                if img_tag:
                    # Ğ†Ğ½Ğ¾Ğ´Ñ– ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ° Ğ² 'src', Ñ–Ğ½Ğ¾Ğ´Ñ– Ğ² 'data-src' (lazy load)
                    img_obj = img_tag.find('img')
                    image_url = img_obj.get('src') or img_obj.get('data-src')
                else:
                    image_url = None

                # 3. Ğ†Ğ½Ğ³Ñ€ĞµĞ´Ñ–Ñ”Ğ½Ñ‚Ğ¸ (Ğ·Ğ±Ğ¸Ñ€Ğ°Ñ”Ğ¼Ğ¾ Ğ²ÑÑ– li Ğ² Ğ±Ğ»Ğ¾Ñ†Ñ– Ñ–Ğ½Ğ³Ñ€ĞµĞ´Ñ–Ñ”Ğ½Ñ‚Ñ–Ğ²)
                ing_div = soup.find('div', class_='ingredients__list')
                ingredients_list = []
                if ing_div:
                    for li in ing_div.find_all('div', class_='checkbox-item'):
                         ingredients_list.append(li.get_text(strip=True))
                
                ingredients_text = "; ".join(ingredients_list)

                # Ğ”Ğ¾Ğ´Ğ°Ñ”Ğ¼Ğ¾ Ğ² Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
                extracted_data.append({
                    "title": title,
                    "url": url,
                    "image_url": image_url,
                    "ingredients": ingredients_text
                })
                print(f"   -> Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾: {title}")

            except Exception as e:
                print(f"âŒ ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ¾Ğ±Ñ†Ñ– {url}: {e}")
        
        return extracted_data

    @task
    def upload_images_to_minio(recipes: list) -> list:
        """
        Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ÑƒÑ” Ñ„Ğ¾Ñ‚Ğ¾ Ğ· Ñ–Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ñƒ Ñ– ĞºĞ»Ğ°Ğ´Ğµ Ğ² MinIO.
        """
        s3_hook = S3Hook(aws_conn_id=S3_CONN_ID)
        
        # ĞŸĞµÑ€ĞµĞºĞ¾Ğ½Ğ°Ñ”Ğ¼Ğ¾ÑÑŒ, Ñ‰Ğ¾ Ğ±Ğ°ĞºĞµÑ‚ Ñ–ÑĞ½ÑƒÑ”
        if not s3_hook.check_for_bucket(BUCKET_IMAGES):
            s3_hook.create_bucket(BUCKET_IMAGES)

        processed_recipes = []

        for item in recipes:
            image_url = item.get("image_url")
            minio_path = None

            if image_url:
                try:
                    # Ğ“ĞµĞ½ĞµÑ€ÑƒÑ”Ğ¼Ğ¾ ÑƒĞ½Ñ–ĞºĞ°Ğ»ÑŒĞ½Ğµ Ñ–Ğ¼'Ñ Ñ„Ğ°Ğ¹Ğ»Ñƒ (Ñ…ĞµÑˆ Ğ²Ñ–Ğ´ URL), Ñ‰Ğ¾Ğ± Ğ½Ğµ Ğ±ÑƒĞ»Ğ¾ Ğ´ÑƒĞ±Ğ»Ñ–Ğ²
                    url_hash = hashlib.md5(item['url'].encode()).hexdigest()
                    file_ext = image_url.split('.')[-1].split('?')[0] # jpg, png...
                    if len(file_ext) > 4: file_ext = "jpg" # Ğ¤Ğ¾Ğ»Ğ»Ğ±ĞµĞº, ÑĞºÑ‰Ğ¾ Ñ€Ğ¾Ğ·ÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ Ğ´Ğ¸Ğ²Ğ½Ğµ
                    
                    filename = f"photos/{url_hash}.{file_ext}"

                    print(f"ğŸ“¥ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ: {image_url}")
                    img_data = requests.get(image_url, stream=True).content
                    
                    s3_hook.load_bytes(
                        bytes_data=img_data,
                        key=filename,
                        bucket_name=BUCKET_IMAGES,
                        replace=True
                    )
                    minio_path = filename
                    print(f"   -> Ğ—Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾ Ğ² MinIO: {filename}")

                except Exception as e:
                    print(f"âš ï¸ ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ Ñ„Ğ¾Ñ‚Ğ¾: {e}")
            
            # ĞĞ½Ğ¾Ğ²Ğ»ÑÑ”Ğ¼Ğ¾ ÑĞ»Ğ¾Ğ²Ğ½Ğ¸Ğº Ğ½Ğ¾Ğ²Ğ¸Ğ¼ ÑˆĞ»ÑÑ…Ğ¾Ğ¼
            item['minio_path'] = minio_path
            processed_recipes.append(item)

        return processed_recipes

    @task
    def save_to_postgres(recipes: list):
        """
        Ğ—Ğ±ĞµÑ€Ñ–Ğ³Ğ°Ñ” Ñ„Ñ–Ğ½Ğ°Ğ»ÑŒĞ½Ñ– Ğ´Ğ°Ğ½Ñ– (Ğ· Ğ¿Ğ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½ÑĞ¼ Ğ½Ğ° MinIO) Ğ² Postgres
        """
        pg_hook = PostgresHook(postgres_conn_id=PG_CONN_ID)
        
        inserted_count = 0
        for item in recipes:
            sql = """
                INSERT INTO parsed_recipes (title, url, image_minio_path, ingredients)
                VALUES (%s, %s, %s, %s)
                ON CONFLICT (url) DO UPDATE 
                SET title = EXCLUDED.title,
                    image_minio_path = EXCLUDED.image_minio_path,
                    ingredients = EXCLUDED.ingredients,
                    parsed_at = NOW();
            """
            pg_hook.run(sql, parameters=(
                item['title'],
                item['url'],
                item['minio_path'],
                item['ingredients']
            ))
            inserted_count += 1
            
        print(f"ğŸ’¾ Ğ£ÑĞ¿Ñ–ÑˆĞ½Ğ¾ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾/Ğ¾Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾ {inserted_count} Ñ€ĞµÑ†ĞµĞ¿Ñ‚Ñ–Ğ² Ñƒ Ğ‘Ğ”.")

    # --- ĞŸĞĞ¢Ğ†Ğš Ğ’Ğ˜ĞšĞĞĞĞĞĞ¯ ---
    init = init_db_schema()
    raw_data = extract_recipe_data(URLS_TO_SCRAPE)
    data_with_images = upload_images_to_minio(raw_data)
    save_final = save_to_postgres(data_with_images)

    # Ğ’ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ÑÑ”Ğ¼Ğ¾ Ğ¿Ğ¾Ñ€ÑĞ´Ğ¾Ğº
    init >> raw_data >> data_with_images >> save_final

scraper_dag()